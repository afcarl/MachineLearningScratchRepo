{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Series Baseball Predictor\n",
    "Amazing bookmarked and forked git repo sources.\n",
    "\n",
    "Key is make features, with a key feature being the Elo Score. The Random Forest is a natural sampler. Also try Logistic Regression. Train it on each world series bracket. Then predict some. Many more data points then if you use the whole bracket vs. just world series winner vs. not. Higher dimensional data, much more info now. \n",
    "\n",
    "Otherwise, one of the posts had the bright idea to Monte Carlo the outcomes and take the mode of the WS winner root node to see whose most likely to win. Or something like that. The Monte Carlo could be very powerful, to simulate the models over and over again, calculating probabilities at each step of the way for each realization. \n",
    "\n",
    "Need to see precisely how Elo works to determine if Monte Carlo is the best route - are win probabilities on an absolute scale or do they always depend on the opponent? Likely the latter. Two teams ranked 95%, when playing each other, will win only 50% of the time. \n",
    "\n",
    "### Elo\n",
    "Probably best to initialize all teams to the same value. 162 games it should be plenty to distinguish the teams. You should make a **separate** script for calculating the elo scores for all teams for all years (since we have the data the rankings should be fixed), and then all you have to do is just load the elo scores.\n",
    "\n",
    "### Retrosheet  \n",
    "Data for elo = http://www.retrosheet.org/gamelogs/index.html  \n",
    "Fields for data = http://www.retrosheet.org/gamelogs/glfields.txt  \n",
    "\n",
    "## To do\n",
    "Fit the right K_elo factors to real data? Do some machine learning for those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import scipy.stats as ss\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_elo_rank(winner_rank, loser_rank, k, penalize_loser=True):\n",
    "    rank_diff = winner_rank - loser_rank\n",
    "    exp = (rank_diff * -1)/400.\n",
    "    odds = 1./(1 + pow(10, exp))\n",
    "    new_winner_rank = round(winner_rank + (k * (1 - odds)))\n",
    "    if penalize_loser:\n",
    "        new_rank_diff = new_winner_rank - winner_rank\n",
    "        new_loser_rank = loser_rank - new_rank_diff\n",
    "    else:\n",
    "        new_loser_rank = loser_rank\n",
    "    if new_loser_rank < 1:\n",
    "        new_loser_rank = 1\n",
    "    return (new_winner_rank, new_loser_rank)\n",
    "\n",
    "#from retrosheet\n",
    "def get_gamelog(year):\n",
    "    cols = [\"Date\",\"Team Away\",\"Away Gm. No.\",\"Team Home\",\"Home Gm. No.\",\"Team Away Score\",\"Team Home Score\"]\n",
    "    GL = pd.read_csv(\"retrosheet_GL/GL\"+str(year)+\".TXT\",usecols=[0,3,5,6,8,9,10],names=cols)\n",
    "    awaywin = GL[\"Team Away Score\"] > GL[\"Team Home Score\"]\n",
    "    homewin = -awaywin\n",
    "    GL.loc[awaywin,\"Winning Team\"] = GL[\"Team Away\"]\n",
    "    GL.loc[awaywin,\"Losing Team\"] = GL[\"Team Home\"]\n",
    "    GL.loc[homewin,\"Winning Team\"] = GL[\"Team Home\"]\n",
    "    GL.loc[homewin,\"Losing Team\"] = GL[\"Team Away\"]\n",
    "    return GL\n",
    "\n",
    "#Super fast with numpy arrays but dreadfully slow with Pandas DataFrames! \n",
    "def calc_season_elo(year,K_i,K_f):\n",
    "    GL = get_gamelog(year)\n",
    "    N = len(GL[\"Team Home\"].unique())\n",
    "    Team, Elo, wins = GL[\"Team Home\"].unique().tolist(), 1500*np.ones(N), np.zeros(N)\n",
    "    K_step = (K_f - K_i)/162.  #impact factor - games at end of season mean more for momentum and such\n",
    "    \n",
    "    for row in GL.itertuples():\n",
    "        index_w = Team.index(row[8])\n",
    "        index_l = Team.index(row[9])\n",
    "        Elo[index_w], Elo[index_l] = calculate_elo_rank(Elo[index_w], Elo[index_l], K_i+row[3]*K_step)\n",
    "        wins[index_w] += 1\n",
    "    Data = zip(Team,Elo,wins)\n",
    "    np.savetxt(\"retrosheet_GL/ELO\"+str(year)+\".TXT\",Data,delimiter=\",\",fmt=\"%s\")\n",
    "    return Data\n",
    "\n",
    "def get_season_elo(year,K_elo_i,K_elo_f):\n",
    "    try:\n",
    "        Data = np.genfromtxt(\"retrosheet_GL/ELO\"+str(year)+\".TXT\",delimiter=\",\",dtype=None)\n",
    "        return Data\n",
    "    except:\n",
    "        print \"couldn't find Elo data for %d, calculating now.\"%year\n",
    "        return calc_season_elo(year,K_elo_i,K_elo_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 1 - Monte Carlo the playoffs!\n",
    "Now let's create the bracket and Monte Carlo the possible winners. Option to have Elo's during the playoffs as well as a linear gradient K factor to give more weight to later games in the season. Calculate \"probability of winning WS\" for each team as the number of times they win / number of attempts.\n",
    "\n",
    "## To do - \n",
    "* need to set up the 1995-1997 brackets correctly. Gawd damnit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#current\n",
    "def get_winner(team1, elo_1, team2, elo_2, series, K):\n",
    "    P_1 = 1./(1 + pow(10,(elo_2 - elo_1) / 400.))\n",
    "    if (series == \"ALWC\") | (series == \"NLWC\"):\n",
    "        w_req = 1\n",
    "    elif (series == \"ALDS1\") | (series == \"ALDS2\") | (series == \"NLDS1\") | (series == \"NLDS2\"):\n",
    "        w_req = 3\n",
    "    else:\n",
    "        w_req = 4\n",
    "    w_1 = 0\n",
    "    w_2 = 0\n",
    "    while (w_1 < w_req) & (w_2 < w_req):\n",
    "        ran = np.random.uniform()\n",
    "        if ran <= P_1:\n",
    "            w_1 += 1\n",
    "        else:\n",
    "            w_2 += 1\n",
    "    if w_1 == w_req:\n",
    "        elo_1, elo_2 = calculate_elo_rank(elo_1, elo_2, K)\n",
    "        return team1, elo_1\n",
    "    else:\n",
    "        elo_2, elo_1 = calculate_elo_rank(elo_2, elo_1, K)\n",
    "        return team2, elo_2\n",
    "\n",
    "def get_bracket(data,year,K_elo):  #1994 no WS, 1995-1997 is really weird seeding. Gonna be super annoying...\n",
    "    Team, Elo, wins = zip(*data)\n",
    "    teams = pd.read_csv(\"csv/team.csv\")\n",
    "    teams = teams.loc[(teams[\"year\"]==year)]\n",
    "    teams = teams.loc[(teams[\"div_win\"]==\"Y\")|(team[\"wc_win\"]==\"Y\")]\n",
    "    \n",
    "    AL = teams.loc[(teams[\"league_id\"]==\"AL\")&(teams[\"rank\"]==1)].sort_values(\"w\")\n",
    "    team_name = AL.loc[:,\"team_id_retro\"].values.tolist()\n",
    "    team_div = AL.loc[:,\"div_id\"].values.tolist()\n",
    "    team_elo = []\n",
    "    for t in team_name:\n",
    "        t_id = Team.index(t)\n",
    "        team_elo.append(Elo[t_id])\n",
    "    if year >= 1994:\n",
    "        WCAL = teams.loc[(teams[\"rank\"]>1)&(teams[\"league_id\"]==\"AL\")].sort_values(\"w\",ascending=False)\n",
    "        if year >= 2012:\n",
    "            WCALteams = WCAL.loc[:,\"team_id_retro\"].values[0:2]\n",
    "            t1 = Team.index(WCALteams[0])\n",
    "            t2 = Team.index(WCALteams[1])\n",
    "            team_name.insert(0,Team[t1])\n",
    "            team_elo.insert(0,Elo[t1])\n",
    "            team_name.insert(0,Team[t2])\n",
    "            team_elo.insert(0,Elo[t2])\n",
    "        else:\n",
    "            if WCAL.loc[:,\"div_id\"].values[0] == team_div[-1]: #stupid 1998-2011 WC rules\n",
    "                team_name[-2], team_name[-1] = team_name[-1], team_name[-2]\n",
    "                team_elo[-2], team_elo[-1] = team_elo[-1], team_elo[-2]\n",
    "            t1 = Team.index(WCAL.loc[:,\"team_id_retro\"].values[0])\n",
    "            team_name.append(Team[t1])\n",
    "            team_elo.append(Elo[t1])\n",
    "\n",
    "    NL = teams.loc[(teams[\"league_id\"]==\"NL\")&(teams[\"rank\"]==1)].sort_values(\"w\")\n",
    "    dummy = NL.loc[:,\"team_id_retro\"].values.tolist()\n",
    "    team_div = NL.loc[:,\"div_id\"].values.tolist()\n",
    "    for t in dummy:\n",
    "        t_id = Team.index(t)\n",
    "        team_name.append(t)\n",
    "        team_elo.append(Elo[t_id])\n",
    "    if year >= 1994:\n",
    "        WCNL = teams.loc[(teams[\"rank\"]>1)&(teams[\"league_id\"]==\"NL\")].sort_values(\"w\",ascending=False)\n",
    "        if year >= 2012:\n",
    "            WCNLteams = WCNL.loc[:,\"team_id_retro\"].values[0:2]\n",
    "            t1 = Team.index(WCNLteams[0])\n",
    "            t2 = Team.index(WCNLteams[1])\n",
    "            team_name.insert(2,Team[t1])\n",
    "            team_elo.insert(2,Elo[t1])\n",
    "            team_name.insert(2,Team[t2])\n",
    "            team_elo.insert(2,Elo[t2])\n",
    "        else:\n",
    "            if WCNL.loc[:,\"div_id\"].values[0] == team_div[-1]: #stupid 1998-2011 WC rules\n",
    "                team_name[-2], team_name[-1] = team_name[-1], team_name[-2]\n",
    "                team_elo[-2], team_elo[-1] = team_elo[-1], team_elo[-2]\n",
    "            t1 = Team.index(WCNL.loc[:,\"team_id_retro\"].values[0])\n",
    "            team_name.append(Team[t1])\n",
    "            team_elo.append(Elo[t1])\n",
    "    return team_name, team_elo\n",
    "\n",
    "def simulate_playoffs(team_name, team_elo, K_elo, year):\n",
    "    series = [\"ALCS\",\"NLCS\",\"WS\"]\n",
    "    if year > 1994:\n",
    "        series = [\"ALDS2\",\"ALDS1\",\"NLDS2\",\"NLDS1\"] + series\n",
    "    if year >= 2012:\n",
    "        series = [\"ALWC\",\"NLWC\"] + series \n",
    "    for i,s in enumerate(series):\n",
    "        winner_team, winner_elo = get_winner(team_name[2*i],team_elo[2*i],team_name[2*i+1],team_elo[2*i+1],s,K_elo)\n",
    "        if s == \"ALWC\":\n",
    "            team_name.insert(7,winner_team)\n",
    "            team_elo.insert(7,winner_elo)           \n",
    "        else:\n",
    "            team_name.append(winner_team)\n",
    "            team_elo.append(winner_elo)\n",
    "    return team_name[-1]\n",
    "\n",
    "def MC_playoffs(year, n_throws, K_elo_season_i, K_elo_season_f, K_elo_playoffs):\n",
    "    ws_winners = []\n",
    "    data = get_season_elo(year, K_elo_season_i, K_elo_season_f) \n",
    "    teams, elo = get_bracket(data, year, K_elo_playoffs)\n",
    "    for i in xrange(0,n_throws):\n",
    "        ws_winners.append(simulate_playoffs(teams[:], elo[:], K_elo_playoffs, year))\n",
    "    return ws_winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature 2 - various W/L statistics about the regular season\n",
    "Maybe a team makes the playoffs, but how are the wins distributed in their season:\n",
    "* How did they do in the last X games of the season (half of the playoffs is about momentum).\n",
    "* Maybe they are very streaky, e.g. 15 game winning streak followed by a 15 game losing streak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_win_stats(year,n_final_games):\n",
    "    GL = get_gamelog(year)\n",
    "    Team = GL[\"Team Home\"].unique().tolist()\n",
    "    EOS_Wins = np.zeros(len(Team))  #end of season wins\n",
    "    game_no = 162 - n_final_games\n",
    "    \n",
    "    WL_dict = {}\n",
    "    for t in Team:\n",
    "        WL_dict[t] = []\n",
    "        \n",
    "    #Get number of wins in last X games of season, prep W/L streaks\n",
    "    for row in GL.itertuples():\n",
    "        WL_dict[row[8]].append(\"W\")\n",
    "        WL_dict[row[9]].append(\"L\")\n",
    "        \n",
    "        if (row[5] >= game_no) | (row[8] >= game_no):\n",
    "            if (row[8] == row[2]) & (row[3] >=game_no):\n",
    "                EOS_Wins[Team.index(row[8])] += 1\n",
    "            elif (row[8] == row[4]) & (row[5] >=game_no):\n",
    "                EOS_Wins[Team.index(row[8])] += 1\n",
    "                \n",
    "    #W/L streak arrays post-processing\n",
    "    WL = [\"W\",\"L\"]\n",
    "    for t in Team:\n",
    "        while len(WL_dict[t]) < 162:  #I guess there are a few missing values?\n",
    "            WL_dict[t].insert(0,WL[np.random.randint(0,2)])\n",
    "        \n",
    "    #get W/L streaks\n",
    "    Win_range = 15\n",
    "    streak_dist = {}\n",
    "    for team, WLrow in WL_dict.iteritems():\n",
    "        dist = np.empty(0)     #Each is a bin from -win_range to +win_range, excl. 0 \n",
    "        WL_prev = WLrow[0]\n",
    "        streak = 0\n",
    "        for val in WLrow:\n",
    "            if val == WL_prev:\n",
    "                streak += 1\n",
    "            else:\n",
    "                index = -1 if WL_prev == \"L\" else 1\n",
    "                dist = np.append(dist, streak*index)\n",
    "                WL_prev = val\n",
    "                streak = 1\n",
    "        index = -1 if WL_prev == \"L\" else 1\n",
    "        dist = np.append(dist, streak*index)\n",
    "        streak_dist[team] = dist\n",
    "    \n",
    "    fc = [\"team\",\"eos_wins\"]\n",
    "    return pd.DataFrame(zip(Team,EOS_Wins), columns=fc, index=Team), streak_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, some Machine Learning!\n",
    "Now that we've spent quite some time creating the features we want to use, it's time to input these features and see how our algorithm performs!\n",
    "\n",
    "### To do:\n",
    "* The above code needs to be generalized to all years.\n",
    "* 1994 - 1997 needs to have the bracket fixed (1994 no playoffs). For now, just exclude that data maybe.\n",
    "* Also, you need to decide whether you're asking \"Who is going to win the WS?\", or \"Who is likely to go deep in the playoffs?\". I think the latter will yield better results. Basically have either separate columns (for whether or not the team made it to each round) or a single column with increasing number for each round they made it to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Calculate and prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "K_elo_season_i = 15\n",
    "K_elo_season_f = 25\n",
    "K_elo_playoffs = 1\n",
    "n_draws = 1000\n",
    "year_cutoff = 1969\n",
    "\n",
    "n_final_games = 10  #10 seems like a good value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data and pre-process\n",
    "team = pd.read_csv(\"csv/team.csv\")\n",
    "team = team[(team[\"div_win\"]==\"Y\")|(team[\"wc_win\"]==\"Y\")] #only want playoff teams\n",
    "team = team[team[\"year\"]>=year_cutoff]                    #1969 = since division series was made\n",
    "team = team[team[\"year\"]!=1981]\n",
    "del_columns = [\"div_id\",\"name\",\"team_id_lahman45\",\"franchise_id\",\"team_id\",\"team_id_br\",\"ppf\",\"bpf\",\"park\",\n",
    "               \"attendance\",\"ghome\",\"g\",\"ab\",\"double\",\"triple\",\"hr\",\"bb\",\"so\",\"sb\",\"cs\",\"hbp\",\"sf\",\"ra\",\"er\",\"era\",\n",
    "              \"cg\",\"sho\",\"sv\",\"ipouts\",\"ha\",\"hra\",\"bba\",\"soa\",\"e\",\"dp\",\"fp\"]\n",
    "team.drop(del_columns, axis=1, inplace=True)\n",
    "\n",
    "#create feature arrays\n",
    "team[\"ws_prob\"] = 0\n",
    "team[\"eos_wins\"] = 0\n",
    "team[\"wl_std\"] = 0\n",
    "team[\"wl_skew\"] = 0\n",
    "\n",
    "#skipped years\n",
    "y_skip = [1981,1994,1995,1996,1997]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the stats. This might take a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get stats\n",
    "for y in range(year_cutoff, 2016):\n",
    "    if y not in y_skip:\n",
    "        winners = MC_playoffs(y, n_draws, K_elo_season_i, K_elo_season_f, K_elo_playoffs)\n",
    "        for name, value in Counter(winners).iteritems():\n",
    "            team.loc[(team[\"team_id_retro\"]==name)&(team[\"year\"]==y),\"ws_prob\"] = value/float(n_draws)\n",
    "\n",
    "        final_wins, streaks = calc_win_stats(y,n_final_games)\n",
    "        for row in final_wins.itertuples():\n",
    "            index = (team[\"team_id_retro\"]==row[1])&(team[\"year\"]==y)\n",
    "            team.loc[index,\"eos_wins\"] = row[2]\n",
    "        for keys, values in streaks.iteritems():\n",
    "            index = (team[\"team_id_retro\"]==keys)&(team[\"year\"]==y)\n",
    "            team.loc[index,\"wl_std\"] = np.std(values)\n",
    "            team.loc[index,\"wl_skew\"] = ss.skew(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#multi-label classification\n",
    "team.loc[team[\"ws_win\"] == \"Y\", \"ws_win\"] = 1\n",
    "team.loc[team[\"ws_win\"] == \"N\", \"ws_win\"] = 0\n",
    "team.loc[pd.isnull(team[\"ws_win\"]), \"ws_win\"] = 0\n",
    "\n",
    "team.loc[team[\"wc_win\"] == \"Y\", \"wc_win\"] = 1\n",
    "team.loc[team[\"wc_win\"] == \"N\", \"wc_win\"] = 0\n",
    "team.loc[pd.isnull(team[\"wc_win\"]), \"wc_win\"] = 0\n",
    "\n",
    "team.loc[team[\"lg_win\"] == \"Y\", \"lg_win\"] = 1\n",
    "team.loc[team[\"lg_win\"] == \"N\", \"lg_win\"] = 0\n",
    "team.loc[pd.isnull(team[\"lg_win\"]), \"lg_win\"] = 0\n",
    "\n",
    "team.loc[team[\"div_win\"] == \"Y\", \"div_win\"] = 1\n",
    "team.loc[team[\"div_win\"] == \"N\", \"div_win\"] = 0\n",
    "team.loc[pd.isnull(team[\"div_win\"]), \"div_win\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - perform RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xcolumns = [\"ws_prob\",\"eos_wins\",\"wl_std\",\"wl_skew\"]\n",
    "ycolumns = [\"lg_win\",\"ws_win\"]\n",
    "y = team[ycolumns].astype(int).values\n",
    "X = team[Xcolumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from gridsearch: {{'max_features': 'sqrt', 'n_estimators': 600, 'min_samples_leaf': 20}} with a score of 0.6988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "cv_s = StratifiedShuffleSplit(y_train,  n_iter=10 , test_size=0.1, random_state=42)\n",
    "rfc = RandomForestClassifier(max_features= 'auto' ,n_estimators=50, oob_score=1, class_weight='balanced') \n",
    "param_grid = { \n",
    "        'n_estimators': [600],\n",
    "        'max_features': ['sqrt'],\n",
    "        'min_samples_leaf': [20]}\n",
    "CV_rfc = GridSearchCV(n_jobs=-1, estimator=rfc, scoring=\"roc_auc\", param_grid=param_grid, cv=cv_s)\n",
    "CV_rfc.fit(X_train, y_train);\n",
    "print(\"Best Parameters from gridsearch: {%s} with a score of %0.4f\" % (CV_rfc.best_params_, CV_rfc.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = CV_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is 0.540293040293\n",
      "OOB score is 0.389705882353\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = model.predict_proba(X_test) #probability that team0 wins (what Kaggle calls team 1, and wants for submission)\n",
    "\n",
    "test_score = metrics.roc_auc_score(y_test[:,0], y_pred[0][:,1], average=\"weighted\") #area under curve from prediction scores\n",
    "print(\"AUC score is {0}\".format(test_score))\n",
    "print(\"OOB score is {0}\".format(model.oob_score_)) #you may not need test/train split with OOB score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature\t\tImportance\n",
      "\n",
      "wl_skew\t\t0.374171\n",
      "ws_prob\t\t0.338568\n",
      "wl_std\t\t0.225095\n",
      "eos_wins\t\t0.062166\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature\\t\\tImportance\\n\")\n",
    "for i in reversed(np.argsort(model.feature_importances_)):\n",
    "    print(\"%s\\t\\t%f\" % (X.columns[i], model.feature_importances_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "Xs = StandardScaler().fit_transform(X)\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs, y, test_size=0.25, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from gridsearch: {{'n_neighbors': 15, 'weights': 'distance'}} with a score of 0.9838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1, weights=\"distance\")\n",
    "cv_s = StratifiedShuffleSplit(ys_train,  n_iter=10 , test_size=0.1, random_state=42)\n",
    "param_grid = { \n",
    "        'n_neighbors': [5,10,15,20,25],\n",
    "        'weights':['distance','uniform']\n",
    "}\n",
    "CV_knn = GridSearchCV(n_jobs=-1, estimator=knn, scoring=\"roc_auc\", param_grid=param_grid, cv=cv_s)\n",
    "CV_knn.fit(Xs_train, ys_train);\n",
    "print(\"Best Parameters from gridsearch: {%s} with a score of %0.4f\" % (CV_knn.best_params_, CV_knn.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Notes\n",
    "\n",
    "### A note about y_pred\n",
    "So for multilabel classification (like in this case, where I fit for lg_win and cs_win), the predict_proba output is arranged like this:  \n",
    "http://stackoverflow.com/questions/17017882/scikit-learn-predict-proba-gives-wrong-answers\n",
    "\n",
    "The model.classes returns:  \n",
    "[array([0, 1]), array([0, 1])]  \n",
    "which tells me how the data is arranged (i.e. two output labels, each with binary output 0/1), and the shape of y_pred is:  \n",
    "(n_choices_per_label, n_samples, n_label)\n",
    "\n",
    "### OOB score\n",
    "It is method similar to Cross-Validation, the advantage being it doesn't require a train/test split of the data. After  decision tree X has been trained, a classification error is calculated using the \"out of bag\" samples, i.e. bootstrapped samples from the original dataset that weren't used to train tree X. Lower OOB score is better.  \n",
    "Links:  \n",
    "* http://stackoverflow.com/questions/18541923/what-is-out-of-bag-error-in-random-forests\n",
    "* Breiman (1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
