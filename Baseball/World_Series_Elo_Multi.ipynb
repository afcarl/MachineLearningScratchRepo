{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Series Baseball Predictor\n",
    "Amazing bookmarked and forked git repo sources.\n",
    "\n",
    "Key is make features, with a key feature being the Elo Score. The Random Forest is a natural sampler. Also try Logistic Regression. Train it on each world series bracket. Then predict some. Many more data points then if you use the whole bracket vs. just world series winner vs. not. Higher dimensional data, much more info now. \n",
    "\n",
    "Otherwise, one of the posts had the bright idea to Monte Carlo the outcomes and take the mode of the WS winner root node to see whose most likely to win. Or something like that. The Monte Carlo could be very powerful, to simulate the models over and over again, calculating probabilities at each step of the way for each realization. \n",
    "\n",
    "Need to see precisely how Elo works to determine if Monte Carlo is the best route - are win probabilities on an absolute scale or do they always depend on the opponent? Likely the latter. Two teams ranked 95%, when playing each other, will win only 50% of the time. \n",
    "\n",
    "### Elo\n",
    "Probably best to initialize all teams to the same value. 162 games it should be plenty to distinguish the teams. You should make a **separate** script for calculating the elo scores for all teams for all years (since we have the data the rankings should be fixed), and then all you have to do is just load the elo scores.\n",
    "\n",
    "### Retrosheet  \n",
    "Data for elo = http://www.retrosheet.org/gamelogs/index.html  \n",
    "Fields for data = http://www.retrosheet.org/gamelogs/glfields.txt  \n",
    "\n",
    "## To do\n",
    "Fit the right K_elo factors to real data? Do some machine learning for those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import scipy.stats as ss\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elo ranking code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_elo_rank(winner_rank, loser_rank, k, penalize_loser=True):\n",
    "    rank_diff = winner_rank - loser_rank\n",
    "    exp = (rank_diff * -1)/400.\n",
    "    odds = 1./(1 + pow(10, exp))\n",
    "    new_winner_rank = round(winner_rank + (k * (1 - odds)))\n",
    "    if penalize_loser:\n",
    "        new_rank_diff = new_winner_rank - winner_rank\n",
    "        new_loser_rank = loser_rank - new_rank_diff\n",
    "    else:\n",
    "        new_loser_rank = loser_rank\n",
    "    if new_loser_rank < 1:\n",
    "        new_loser_rank = 1\n",
    "    return (new_winner_rank, new_loser_rank)\n",
    "\n",
    "#from retrosheet\n",
    "def get_gamelog(year):\n",
    "    cols = [\"Date\",\"Team Away\",\"Away Gm. No.\",\"Team Home\",\"Home Gm. No.\",\"Team Away Score\",\"Team Home Score\"]\n",
    "    GL = pd.read_csv(\"retrosheet_GL/GL\"+str(year)+\".TXT\",usecols=[0,3,5,6,8,9,10],names=cols)\n",
    "    awaywin = GL[\"Team Away Score\"] > GL[\"Team Home Score\"]\n",
    "    homewin = -awaywin\n",
    "    GL.loc[awaywin,\"Winning Team\"] = GL[\"Team Away\"]\n",
    "    GL.loc[awaywin,\"Losing Team\"] = GL[\"Team Home\"]\n",
    "    GL.loc[homewin,\"Winning Team\"] = GL[\"Team Home\"]\n",
    "    GL.loc[homewin,\"Losing Team\"] = GL[\"Team Away\"]\n",
    "    return GL\n",
    "\n",
    "#Super fast with numpy arrays but dreadfully slow with Pandas DataFrames! \n",
    "def calc_season_elo(year,K_i,K_f):\n",
    "    GL = get_gamelog(year)\n",
    "    N = len(GL[\"Team Home\"].unique())\n",
    "    Team, Elo, wins = GL[\"Team Home\"].unique().tolist(), 1500*np.ones(N), np.zeros(N)\n",
    "    K_step = (K_f - K_i)/162.  #impact factor - games at end of season mean more for momentum and such\n",
    "    \n",
    "    for row in GL.itertuples():\n",
    "        index_w = Team.index(row[8])\n",
    "        index_l = Team.index(row[9])\n",
    "        Elo[index_w], Elo[index_l] = calculate_elo_rank(Elo[index_w], Elo[index_l], K_i+row[3]*K_step)\n",
    "        wins[index_w] += 1\n",
    "    Data = zip(Team,Elo,wins)\n",
    "    np.savetxt(\"retrosheet_GL/ELO\"+str(year)+\".TXT\",Data,delimiter=\",\",fmt=\"%s\")\n",
    "    return Data\n",
    "\n",
    "def get_season_elo(year,K_elo_i,K_elo_f):\n",
    "    try:\n",
    "        Data = np.genfromtxt(\"retrosheet_GL/ELO\"+str(year)+\".TXT\",delimiter=\",\",dtype=None)\n",
    "        return Data\n",
    "    except:\n",
    "        print \"couldn't find Elo data for %d, calculating now.\"%year\n",
    "        return calc_season_elo(year,K_elo_i,K_elo_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 1 - Monte Carlo the playoffs\n",
    "Here we set up the playoff bracket for each year and Monte Carlo the playoffs X times. There's an option to have Elo's during the playoffs, as well as a linear gradient K factor to give more weight to later games in the season. Outputs the probability of each team in winning the WS, calculated as the number of times they win the WS divided by the total number of attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#current\n",
    "def get_winner(team1, elo_1, team2, elo_2, series, K):\n",
    "    P_1 = 1./(1 + pow(10,(elo_2 - elo_1) / 400.))\n",
    "    if (series == \"ALWC\") | (series == \"NLWC\"):\n",
    "        w_req = 1\n",
    "    elif (series == \"ALDS1\") | (series == \"ALDS2\") | (series == \"NLDS1\") | (series == \"NLDS2\"):\n",
    "        w_req = 3\n",
    "    else:\n",
    "        w_req = 4\n",
    "    w_1 = 0\n",
    "    w_2 = 0\n",
    "    while (w_1 < w_req) & (w_2 < w_req):\n",
    "        ran = np.random.uniform()\n",
    "        if ran <= P_1:\n",
    "            w_1 += 1\n",
    "        else:\n",
    "            w_2 += 1\n",
    "    if w_1 == w_req:\n",
    "        elo_1, elo_2 = calculate_elo_rank(elo_1, elo_2, K)\n",
    "        return team1, elo_1\n",
    "    else:\n",
    "        elo_2, elo_1 = calculate_elo_rank(elo_2, elo_1, K)\n",
    "        return team2, elo_2\n",
    "\n",
    "def get_bracket(data,year,K_elo):  #1994 no WS, 1995-1997 is really weird seeding. Gonna be super annoying...\n",
    "    Team, Elo, wins = zip(*data)\n",
    "    teams = pd.read_csv(\"csv/team.csv\")\n",
    "    teams = teams.loc[(teams[\"year\"]==year)]\n",
    "    teams = teams.loc[(teams[\"div_win\"]==\"Y\")|(team[\"wc_win\"]==\"Y\")]\n",
    "    \n",
    "    AL = teams.loc[(teams[\"league_id\"]==\"AL\")&(teams[\"rank\"]==1)].sort_values(\"w\")\n",
    "    team_name = AL.loc[:,\"team_id_retro\"].values.tolist()\n",
    "    team_div = AL.loc[:,\"div_id\"].values.tolist()\n",
    "    team_elo = []\n",
    "    for t in team_name:\n",
    "        t_id = Team.index(t)\n",
    "        team_elo.append(Elo[t_id])\n",
    "    if year > 1997:\n",
    "        WCAL = teams.loc[(teams[\"rank\"]>1)&(teams[\"league_id\"]==\"AL\")].sort_values(\"w\",ascending=False)\n",
    "        if year >= 2012:\n",
    "            WCALteams = WCAL.loc[:,\"team_id_retro\"].values[0:2]\n",
    "            t1 = Team.index(WCALteams[0])\n",
    "            t2 = Team.index(WCALteams[1])\n",
    "            team_name.insert(0,Team[t1])\n",
    "            team_elo.insert(0,Elo[t1])\n",
    "            team_name.insert(0,Team[t2])\n",
    "            team_elo.insert(0,Elo[t2])\n",
    "        else:\n",
    "            if WCAL.loc[:,\"div_id\"].values[0] == team_div[-1]: #stupid 1998-2011 WC rules\n",
    "                team_name[-2], team_name[-1] = team_name[-1], team_name[-2]\n",
    "                team_elo[-2], team_elo[-1] = team_elo[-1], team_elo[-2]\n",
    "            t1 = Team.index(WCAL.loc[:,\"team_id_retro\"].values[0])\n",
    "            team_name.append(Team[t1])\n",
    "            team_elo.append(Elo[t1])\n",
    "\n",
    "    NL = teams.loc[(teams[\"league_id\"]==\"NL\")&(teams[\"rank\"]==1)].sort_values(\"w\")\n",
    "    dummy = NL.loc[:,\"team_id_retro\"].values.tolist()\n",
    "    team_div = NL.loc[:,\"div_id\"].values.tolist()\n",
    "    for t in dummy:\n",
    "        t_id = Team.index(t)\n",
    "        team_name.append(t)\n",
    "        team_elo.append(Elo[t_id])\n",
    "    if (year >= 1995)&(year <= 1997): #too hard to make rules for, just hardcode AL/NL teams together\n",
    "        team_div = [['SEA','NYA','CLE','BOS','ATL','COL','CIN','LAN'],\n",
    "                    ['NYA','TEX','BAL','CLE','ATL','LAN','SDN','SLN'],\n",
    "                    ['CLE','NYA','BAL','SEA','ATL','HOU','SFN','FLO']]\n",
    "        team_name = team_div[year-1995]\n",
    "        team_elo = []\n",
    "        for t in team_name:\n",
    "            team_elo.append(Elo[Team.index(t)])\n",
    "    elif year > 1997:\n",
    "        WCNL = teams.loc[(teams[\"rank\"]>1)&(teams[\"league_id\"]==\"NL\")].sort_values(\"w\",ascending=False)\n",
    "        if year >= 2012:\n",
    "            WCNLteams = WCNL.loc[:,\"team_id_retro\"].values[0:2]\n",
    "            t1 = Team.index(WCNLteams[0])\n",
    "            t2 = Team.index(WCNLteams[1])\n",
    "            team_name.insert(2,Team[t1])\n",
    "            team_elo.insert(2,Elo[t1])\n",
    "            team_name.insert(2,Team[t2])\n",
    "            team_elo.insert(2,Elo[t2])\n",
    "        else:\n",
    "            if WCNL.loc[:,\"div_id\"].values[0] == team_div[-1]: #stupid 1998-2011 WC rules\n",
    "                team_name[-2], team_name[-1] = team_name[-1], team_name[-2]\n",
    "                team_elo[-2], team_elo[-1] = team_elo[-1], team_elo[-2]\n",
    "            t1 = Team.index(WCNL.loc[:,\"team_id_retro\"].values[0])\n",
    "            team_name.append(Team[t1])\n",
    "            team_elo.append(Elo[t1])\n",
    "    return team_name, team_elo\n",
    "\n",
    "def simulate_playoffs(team_name, team_elo, K_elo, year):\n",
    "    series = [\"ALCS\",\"NLCS\",\"WS\"]\n",
    "    if year > 1994:\n",
    "        series = [\"ALDS2\",\"ALDS1\",\"NLDS2\",\"NLDS1\"] + series\n",
    "    if year >= 2012:\n",
    "        series = [\"ALWC\",\"NLWC\"] + series \n",
    "    for i,s in enumerate(series):\n",
    "        winner_team, winner_elo = get_winner(team_name[2*i],team_elo[2*i],team_name[2*i+1],team_elo[2*i+1],s,K_elo)\n",
    "        if s == \"ALWC\":\n",
    "            team_name.insert(7,winner_team)\n",
    "            team_elo.insert(7,winner_elo)           \n",
    "        else:\n",
    "            team_name.append(winner_team)\n",
    "            team_elo.append(winner_elo)\n",
    "    return team_name[-1]\n",
    "\n",
    "def MC_playoffs(year, n_throws, K_elo_season_i, K_elo_season_f, K_elo_playoffs):\n",
    "    ws_winners = []\n",
    "    data = get_season_elo(year, K_elo_season_i, K_elo_season_f) \n",
    "    teams, elo = get_bracket(data, year, K_elo_playoffs)\n",
    "    for i in xrange(0,n_throws):\n",
    "        ws_winners.append(simulate_playoffs(teams[:], elo[:], K_elo_playoffs, year))\n",
    "    return ws_winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature 2 - various W/L statistics about the regular season\n",
    "Maybe a team makes the playoffs, but how are the wins distributed in their season:\n",
    "* How did they do in the last X games of the season (half of the playoffs is about momentum).\n",
    "* Maybe they are very streaky, e.g. 15 game winning streak followed by a 15 game losing streak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_win_stats(year,n_final_games):\n",
    "    GL = get_gamelog(year)\n",
    "    Team = GL[\"Team Home\"].unique().tolist()\n",
    "    EOS_Wins = np.zeros(len(Team))      #end of season wins\n",
    "    EOS_Runs = np.zeros((len(Team),2))  #end of season wins\n",
    "    game_no = 162 - n_final_games\n",
    "    \n",
    "    WL_dict = {}\n",
    "    for t in Team:\n",
    "        WL_dict[t] = []  \n",
    "    #Get number of wins in last X games of season, prep W/L streaks\n",
    "    for row in GL.itertuples():\n",
    "        WL_dict[row[8]].append(\"W\")\n",
    "        WL_dict[row[9]].append(\"L\")\n",
    "        \n",
    "        if (row[3] >= game_no) | (row[5] >= game_no):\n",
    "            EOS_Runs[Team.index(row[2]),0] += row[6]\n",
    "            EOS_Runs[Team.index(row[2]),1] += row[7]\n",
    "            EOS_Runs[Team.index(row[4]),0] += row[7]\n",
    "            EOS_Runs[Team.index(row[4]),1] += row[6]\n",
    "            if (row[8] == row[2]) & (row[3] >=game_no):\n",
    "                EOS_Wins[Team.index(row[8])] += 1\n",
    "            elif (row[8] == row[4]) & (row[5] >=game_no):\n",
    "                EOS_Wins[Team.index(row[8])] += 1\n",
    "                \n",
    "    #W/L streak arrays post-processing\n",
    "    WL = [\"W\",\"L\"]\n",
    "    for t in Team:\n",
    "        while len(WL_dict[t]) < 162:  #I guess there are a few missing values?\n",
    "            WL_dict[t].insert(0,WL[np.random.randint(0,2)])\n",
    "        \n",
    "    #get W/L streaks\n",
    "    Win_range = 15\n",
    "    streak_dist = {}\n",
    "    for team, WLrow in WL_dict.iteritems():\n",
    "        dist = np.empty(0)     #Each is a bin from -win_range to +win_range, excl. 0 \n",
    "        WL_prev = WLrow[0]\n",
    "        streak = 0\n",
    "        for val in WLrow:\n",
    "            if val == WL_prev:\n",
    "                streak += 1\n",
    "            else:\n",
    "                index = -1 if WL_prev == \"L\" else 1\n",
    "                dist = np.append(dist, streak*index)\n",
    "                WL_prev = val\n",
    "                streak = 1\n",
    "        index = -1 if WL_prev == \"L\" else 1\n",
    "        dist = np.append(dist, streak*index)\n",
    "        streak_dist[team] = dist\n",
    "    \n",
    "    fc = [\"team\",\"eos_wins\",\"eos_runs_ratio\"]\n",
    "    return pd.DataFrame(zip(Team,EOS_Wins,EOS_Runs[:,0]/EOS_Runs[:,1]), columns=fc, index=Team), streak_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 3 - Great Managers and All-Star Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_allstars_and_managers(team, year_cutoff):\n",
    "    allstars = pd.read_csv(\"csv/all_star.csv\")\n",
    "    allstars = allstars[allstars[\"year\"]>year_cutoff]\n",
    "    allstars.loc[allstars[\"team_id\"]==\"ML4\",\"team_id\"] == \"MIL\"\n",
    "    allstars.loc[allstars[\"team_id\"]==\"LAA\",\"team_id\"] == \"ANA\"\n",
    "\n",
    "    team[\"n_allstars\"] = 0\n",
    "    for row in allstars.itertuples():\n",
    "        team.loc[(team[\"year\"]==row[2])&(team[\"team_id_retro\"]==row[5]),\"n_allstars\"] += 1\n",
    "    \n",
    "    return team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "It's time to start reading in some data, and preparing our features for the various machine learning algorithms we're going to use.\n",
    "\n",
    "The cell below contains the key parameters needed to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "K_elo_season_i = 15\n",
    "K_elo_season_f = 30\n",
    "K_elo_playoffs = K_elo_season_f\n",
    "n_draws = 1000\n",
    "year_cutoff = 1969  #1969 = beginning of modern MLB era\n",
    "\n",
    "n_final_games = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data and pre-process\n",
    "team = pd.read_csv(\"csv/team.csv\")\n",
    "team = team[(team[\"div_win\"]==\"Y\")|(team[\"wc_win\"]==\"Y\")] #only want playoff teams\n",
    "team = team[team[\"year\"]>=year_cutoff]                    #1969 = since division series was made\n",
    "team = team[team[\"year\"]!=1981]\n",
    "del_columns = [\"div_id\",\"name\",\"team_id_lahman45\",\"franchise_id\",\"team_id\",\"team_id_br\",\"ppf\",\"bpf\",\"park\",\n",
    "               \"attendance\",\"ghome\",\"g\",\"ab\",\"double\",\"triple\",\"hr\",\"bb\",\"so\",\"sb\",\"cs\",\"hbp\",\"sf\",\"ra\",\"er\",\"era\",\n",
    "              \"cg\",\"sho\",\"sv\",\"ipouts\",\"ha\",\"hra\",\"bba\",\"soa\",\"e\",\"dp\",\"fp\"]\n",
    "team.drop(del_columns, axis=1, inplace=True)\n",
    "\n",
    "#create feature arrays\n",
    "team[\"ws_prob\"] = 0\n",
    "team[\"eos_wins\"] = 0\n",
    "team[\"eos_runs_ratio\"] = 0\n",
    "team[\"wl_std\"] = 0\n",
    "team[\"wl_skew\"] = 0\n",
    "\n",
    "#skipped years\n",
    "y_skip = [1981,1994]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the stats. This might take a minute.\n",
    "\n",
    "Other stats to consider:  \n",
    "* Something about the manager, experience?\n",
    "* Number of all stars - sometimes playoffs boil down to a few key events from a few key players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ws_prob (elo), end of season stats, W/L season streak stats\n",
    "for y in range(year_cutoff, 2016):\n",
    "    if y not in y_skip:\n",
    "        winners = MC_playoffs(y, n_draws, K_elo_season_i, K_elo_season_f, K_elo_playoffs)\n",
    "        for name, value in Counter(winners).iteritems():\n",
    "            team.loc[(team[\"team_id_retro\"]==name)&(team[\"year\"]==y),\"ws_prob\"] = value/float(n_draws)\n",
    "\n",
    "        final_wins, streaks = calc_win_stats(y,n_final_games)\n",
    "        for row in final_wins.itertuples():\n",
    "            index = (team[\"team_id_retro\"]==row[1])&(team[\"year\"]==y)\n",
    "            team.loc[index,\"eos_wins\"] = row[2]\n",
    "            team.loc[index,\"eos_runs_ratio\"] = row[3]\n",
    "        for keys, values in streaks.iteritems():\n",
    "            index = (team[\"team_id_retro\"]==keys)&(team[\"year\"]==y)\n",
    "            team.loc[index,\"wl_std\"] = np.std(values)\n",
    "            team.loc[index,\"wl_skew\"] = ss.skew(values)\n",
    "\n",
    "#get all stars, manager stats\n",
    "team = get_allstars_and_managers(team, year_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#multi-label classification\n",
    "team.loc[team[\"ws_win\"] == \"Y\", \"ws_win\"] = 1\n",
    "team.loc[team[\"ws_win\"] == \"N\", \"ws_win\"] = 0\n",
    "team.loc[pd.isnull(team[\"ws_win\"]), \"ws_win\"] = 0\n",
    "\n",
    "team.loc[team[\"lg_win\"] == \"Y\", \"lg_win\"] = 1\n",
    "team.loc[team[\"lg_win\"] == \"N\", \"lg_win\"] = 0\n",
    "team.loc[pd.isnull(team[\"lg_win\"]), \"lg_win\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onto Machine Learning\n",
    "Now that we've spent quite some time creating the features we want to use, it's time to input these features and see how our algorithm performs for predicting **who will make it to the WS final**.\n",
    "\n",
    "### Split Data\n",
    "Here were going to try splitting the data into train/test, but with the condition that no teams from the same year are ever separated. Might make a difference as far as keeping all the biases of one year together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xcolumns = [\"ws_prob\",\"eos_wins\",\"eos_runs_ratio\",\"wl_std\",\"wl_skew\",\"n_allstars\"]\n",
    "#ycolumns = [\"lg_win\",\"ws_win\"]\n",
    "#y = team[ycolumns].astype(int).values\n",
    "y = team[\"lg_win\"].astype(int).values\n",
    "X = team[Xcolumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from gridsearch: {{'max_features': 'log2', 'n_estimators': 600, 'min_samples_leaf': 20}} with a score of 0.5748\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "cv_s = StratifiedShuffleSplit(y_train,  n_iter=10 , test_size=0.15, random_state=42)\n",
    "rfc = RandomForestClassifier(max_features= 'auto' ,n_estimators=50, oob_score=1, class_weight='balanced') \n",
    "param_grid = { \n",
    "        'n_estimators': [600],\n",
    "        'max_features': ['sqrt','log2'],\n",
    "        'min_samples_leaf': [5,10,20]}\n",
    "CV_rfc = GridSearchCV(n_jobs=-1, estimator=rfc, scoring=\"roc_auc\", param_grid=param_grid, cv=cv_s)\n",
    "CV_rfc.fit(X_train, y_train);\n",
    "print(\"Best Parameters from gridsearch: {%s} with a score of %0.4f\" % (CV_rfc.best_params_, CV_rfc.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelrfc = CV_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is 0.550264550265\n",
      "OOB score is 0.554112554113\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = modelrfc.predict_proba(X_test) #probability that team0 wins (what Kaggle calls team 1, and wants for submission)\n",
    "\n",
    "#test_score = metrics.roc_auc_score(y_test[:,0], y_pred[0][:,1], average=\"weighted\") #area under curve from prediction scores\n",
    "test_score = metrics.roc_auc_score(y_test, y_pred[:,1], average=\"weighted\")\n",
    "print(\"AUC score is {0}\".format(test_score))\n",
    "print(\"OOB score is {0}\".format(modelrfc.oob_score_)) #you may not(?) need test/train split with OOB score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature\t\tImportance\n",
      "\n",
      "ws_prob\t\t0.256548\n",
      "wl_std\t\t0.224475\n",
      "n_allstars\t\t0.154863\n",
      "eos_runs_ratio\t\t0.150438\n",
      "wl_skew\t\t0.140583\n",
      "eos_wins\t\t0.073095\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature\\t\\tImportance\\n\")\n",
    "for i in reversed(np.argsort(modelrfc.feature_importances_)):\n",
    "    print(\"%s\\t\\t%f\" % (X.columns[i], modelrfc.feature_importances_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1111993d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0GSVBgIkiQA/h9TZZpXPwy/RgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1110c4a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_pred[:,1],y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First scale data\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "Xs = StandardScaler().fit_transform(X)\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs, y, test_size=0.15, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from gridsearch: {{'n_neighbors': 20, 'weights': 'uniform'}} with a score of 0.4672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1, weights=\"distance\")\n",
    "cv_s = StratifiedShuffleSplit(ys_train,  n_iter=10 , test_size=0.2, random_state=42)\n",
    "param_grid = { \n",
    "        'n_neighbors': [5,10,15,20],\n",
    "        'weights':['distance','uniform']\n",
    "}\n",
    "CV_knn = GridSearchCV(n_jobs=-1, estimator=knn, scoring=\"roc_auc\", param_grid=param_grid, cv=cv_s)\n",
    "CV_knn.fit(Xs_train, ys_train);\n",
    "print(\"Best Parameters from gridsearch: {%s} with a score of %0.4f\" % (CV_knn.best_params_, CV_knn.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelknn = CV_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is 0.490740740741\n"
     ]
    }
   ],
   "source": [
    "ys_pred = modelknn.predict_proba(Xs_test) #probability that team0 wins (what Kaggle calls team 1, and wants for submission)\n",
    "\n",
    "test_score_knn = metrics.roc_auc_score(ys_test, ys_pred[:,1], average=\"weighted\")\n",
    "#test_score = metrics.roc_auc_score(ys_test[:,0], ys_pred[0][:,1], average=\"weighted\") #area under curve from prediction scores\n",
    "print(\"AUC score is {0}\".format(test_score_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x113bdb1d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCmYISFLBDAFJKpghIEkFMwQkqWD/D3mwBg+BcTuZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113abfdd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(ys_pred[:,1],ys_test)\n",
    "#pd.DataFrame([ys_pred[:,1], ys_test]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Notes\n",
    "\n",
    "### A note about y_pred\n",
    "So for multilabel classification (like in this case, where I fit for lg_win and cs_win), the predict_proba output is arranged like this:  \n",
    "http://stackoverflow.com/questions/17017882/scikit-learn-predict-proba-gives-wrong-answers\n",
    "\n",
    "The model.classes returns:  \n",
    "[array([0, 1]), array([0, 1])]  \n",
    "which tells me how the data is arranged (i.e. two output labels, each with binary output 0/1), and the shape of y_pred is:  \n",
    "(n_choices_per_label, n_samples, n_label)\n",
    "\n",
    "### OOB score\n",
    "It is method similar to Cross-Validation, the advantage being it doesn't require a train/test split of the data. After  decision tree X has been trained, a classification error is calculated using the \"out of bag\" samples, i.e. bootstrapped samples from the original dataset that weren't used to train tree X. Lower OOB score is better.  \n",
    "Links:  \n",
    "* http://stackoverflow.com/questions/18541923/what-is-out-of-bag-error-in-random-forests\n",
    "* Breiman (1996)\n",
    "\n",
    "### Next step maybe? \n",
    "* Maybe add one or two features, but not too many more. Maybe a few from your old attempt. But I think you need to train each series separately maybe? Randomize years, but have conditions where you never separate teams from the same year. It helps include all the distinct noise in each particular year. All teams from the same year have biases and correlations that are related to one another. And so maybe they cancel out a bit? At the very least, Elo scores from similar years probably are easier to compare directly, and are apples to apples. An elo of 1500 from e.g. the 1960s may be an orange to e.g. elo of 1500 from 2006, which is an apple. But can that be done easily?  \n",
    "* You also need to figure more about the KNN. Why did it have such a high accuracy score and bad AUC score (lower the better, right?)? Did it just fit all the noise? Did the KNN even fit the data properly? Can it recognize multi label? How does it do it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train/test split data, but keep teams from same year together\n",
    "#test_size = 0.2\n",
    "\n",
    "#np.random.seed(42)\n",
    "#years = team[\"year\"].unique()\n",
    "#rand = np.random.rand(len(years))\n",
    "\n",
    "#train = team[\"year\"].isin(years[rand>test_size])\n",
    "#test = team[\"year\"].isin(years[rand<=test_size])\n",
    "#X_train, y_train = team.loc[train, Xcolumns].values, team.loc[train, \"lg_win\"].astype(int).values\n",
    "#X_test, y_test = team.loc[test, Xcolumns].values, team.loc[test, \"lg_win\"].astype(int).values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
